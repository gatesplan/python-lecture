{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 뉴럴 네트워크?\n",
    "\n",
    "이번 강의에서 여러분은 현대 머신러닝의 시작지점인 뉴럴네트워크를 다루는 방법을 배운다."
   ],
   "id": "55a054a5ac875887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 전처리된 타이타닉 데이터셋 로드\n",
    "import pandas as pd\n",
    "titanic = pd.read_csv('preprocessed_titanic.csv', index_col=0)\n",
    "\n",
    "# xs, ys 분리\n",
    "xs, ys = titanic.drop(columns=['alive', 'survived']), titanic['survived']\n",
    "\n",
    "# tts\n",
    "from sklearn.model_selection import train_test_split\n",
    "xs_train, xs_test, ys_train, ys_test = train_test_split(xs, ys, test_size=0.2)\n",
    "\n",
    "# 준비 끝!"
   ],
   "id": "cfb2b60fa2e6f1a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(xs.columns)",
   "id": "c61702ce9f35f1d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 쉬운 길\n",
    "\n",
    "장난감 만들기"
   ],
   "id": "7f9cdbafb8d47b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## 11 -> 30 -> 30 -> 30 -> 1\n",
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(30, 30, 30),\n",
    "    max_iter=300,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    ")\n",
    "\n",
    "clf.fit(xs_train, ys_train)\n",
    "y_pred = clf.predict(xs_test)\n",
    "\n",
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(ys_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ],
   "id": "80f178ba84903c11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "여러분은 이제부터 Tensor 객체를 다루는 방법을 먼저 배워야 한다.\n",
    "\n",
    "데이터를 Tensor(행렬)로 변환하고, 조작하고 등등의 기본 작업을 수행할 줄 알아야 한다."
   ],
   "id": "a97befc95a11ffce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tensor 선언\n",
    "\n",
    "Tensor(행렬)은 PyTorch의 기본 데이터 구조이다.\n",
    "\n",
    "PyTorch는 Tensor를 사용하여 데이터를 표현하고, 연산을 수행한다.\n",
    "\n",
    "Tensor는 다차원 배열로, NumPy의 ndarray와 유사하며, 이것으로 수치 연산을 수행하고 딥러닝 모델을 구축한다.\n",
    "\n",
    "Tensor는 CPU와 GPU에서 모두 사용할 수 있으며, GPU를 사용하여 연산을 가속화할 수 있다.\n",
    "\n",
    "여기서 우리는 Tensor를 선언하는 기본적인 방법을 배우고, 기존 데이터를 Tensor로 변환할 것이다."
   ],
   "id": "7a79dbefb44e1f68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import Tensor\n",
    "from torch import ones, randn, zeros\n",
    "\n",
    "print(Tensor([[2, 3, 3],\n",
    "              [4, 5, -1]]).shape)"
   ],
   "id": "2e76408875bc8553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(Tensor([1]).shape)\n",
    "print(Tensor([[1]]).shape)\n",
    "print(Tensor([[[1]]]).shape)"
   ],
   "id": "114adecbbff49eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2x2 tensor 생성\n",
    "print(Tensor([[1, 2],\n",
    "              [3, 4]]))\n",
    "\n",
    "# 4x2 tensor 생성\n",
    "print(Tensor([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6],\n",
    "              [7, 8]]))"
   ],
   "id": "cf3d05c8c8a31ea7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "계속 이렇게 만들어야 하나요?\n",
    "\n",
    "**네**"
   ],
   "id": "a22602aa1d7a5382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 빈 tensor 만들기\n",
    "from torch import zeros, ones, randn\n",
    "\n",
    "# 2x2 tensor zerofill\n",
    "print(zeros(2, 2))"
   ],
   "id": "9afc5c9e785ae58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1로 채워진 tensor 만들기\n",
    "print(ones(2, 2))\n",
    "\n",
    "# 4x2x6 tensor 생성\n",
    "print(ones(4, 2, 6))"
   ],
   "id": "ef86c99c1be911b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 랜덤한 값으로 채워진 tensor 만들기\n",
    "print(randn(3, 6))"
   ],
   "id": "61722611ed229e3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(type(xs_train))\n",
    "print(type(xs_train.values))\n",
    "print(type(Tensor(xs_train.values)))\n",
    "\n",
    "Tensor(xs_train.values)"
   ],
   "id": "5eb96add88dadcd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 텐서 연산\n",
    "\n",
    "두 텐서간의 연산을 지원한다."
   ],
   "id": "c611127ebfbac0e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t1 = Tensor([[1, 2],\n",
    "             [3, 4]])\n",
    "t1"
   ],
   "id": "8f0da7832bb315e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 스칼라 덧셈, 뺄셈, 곱셈, 나눗셈\n",
    "t1 + 1, t1 - 1, t1 * 2, t1 / 2"
   ],
   "id": "ce029eeb4d5e8b87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vec = Tensor([-2])\n",
    "\n",
    "t1 / vec"
   ],
   "id": "857a72cee08cb339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 벡터곱\n",
    "vec = Tensor([1, -1])\n",
    "\n",
    "t2 = Tensor([[1, 2, 3],\n",
    "             [4, 5, 6]])\n",
    "t3 = Tensor([1, 2, 3])\n",
    "t2.shape, t3.shape"
   ],
   "id": "f6eefd4de82f99b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 같은 크기\n",
    "t2 = Tensor([[1, -1],\n",
    "             [2, -2]])\n",
    "\n",
    "t1 / t2"
   ],
   "id": "a54be81b9620f537",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 컴까기\n",
    "t4 = ones(4, 2, 3)\n",
    "t4.shape"
   ],
   "id": "cf8137f1a04a90e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t5 = Tensor([[[1, 2, 3],\n",
    "             [4, 5, 6]],\n",
    "\n",
    "             [[-1, -2, -3],\n",
    "             [-4, -5, -6]]])\n",
    "t5.shape"
   ],
   "id": "75ed4e111a1d7336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "(t4.reshape(-1, 2, 2, 3) * t5).reshape(-1, 2, 3).shape",
   "id": "4a3d9bd792e1f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "t6 = ones(7)",
   "id": "f1fe52271f286560",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "t1.matmul(t2)  # 행렬 곱셈",
   "id": "a6166994c87e1da8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 다른 크기\n",
    "t3 = Tensor([[1, 2],\n",
    "             [3, 4],\n",
    "             [5, 6],\n",
    "             [7, 8]])\n",
    "\n",
    "t1 + t3, t1 - t3, t1 * t3, t1 / t3  # 브로드캐스팅 실패"
   ],
   "id": "a40b75237e4d84d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## `Tensor.reshape(d, i, m, e, n, s, i, o, n)`\n",
    "\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`Tensor.reshape()`\n",
    "중요함"
   ],
   "id": "f0f904ce773235a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# reshape (재구성)\n",
    "t = Tensor([[1, 2],\n",
    "            [3, 4],\n",
    "            [5, 6]])\n",
    "print(t)"
   ],
   "id": "a0fbc95be85b4376",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "t.flatten()  # 1차원으로 평탄화",
   "id": "e1d4b05a8fbb5429",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "t.reshape(1, 2, 1, 2, 3)",
   "id": "6dc52c88968b691f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "t = ones(3, 4, 5, 2, 3)\n",
    "t.reshape(10, -1).shape"
   ],
   "id": "253542bbdac60820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "t.reshape(3, -1)  # 3행, 열은 되는데로",
   "id": "3e4370310b99f9d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xs_train_tensor = Tensor(xs_train.values)\n",
    "xs_test_tensor = Tensor(xs_test.values)\n",
    "ys_train_tensor = Tensor(ys_train.values)\n",
    "ys_test_tensor = Tensor(ys_test.values)"
   ],
   "id": "1b19e5342d0e8f1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(\n",
    "    xs_train_tensor, ys_train_tensor\n",
    ")  # 훈련용 x, y값을 묶어서 데이터셋 생성\n",
    "\n",
    "for_train = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")"
   ],
   "id": "8f5b65dbee2493c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Practice 1.\n",
    "\n",
    "1. `clean_?` 데이터셋에서 분리한 xs_train, xs_test, ys_train, ys_test를 각각 Tensor로 변환한다.\n",
    "2. xs_train, ys_train을 DataLoader에 전달하여 배치 크기 32짜리 훈련 데이터셋을 만든다."
   ],
   "id": "6269ce88f804086e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 네트워크 생성\n",
    "\n",
    "이제 여러분은 Tensor를 다루는 방법을 배웠다.\n",
    "\n",
    "이제는 뉴럴 네트워크를 생성하는 방법을 배워야 한다.\n",
    "\n",
    "이 단계에서 배우는 두 가지 개념은 **레이어**와 **층**이다."
   ],
   "id": "9cb014ff1892173f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicModel, self).__init__()\n",
    "\n",
    "        self.a = nn.Linear(11, 30)\n",
    "        self.b = nn.Linear(30, 20)\n",
    "        self.c = nn.Linear(20, 1)\n",
    "\n",
    "tm = TitanicModel()\n",
    "tm"
   ],
   "id": "b1c7d4eca9b5641e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4개의 값을 받아 1개의 값을 출력하는 모델을 정의한다.\n",
    "# 4->10->10->1 총 3층으로 이뤄진 모델\n",
    "\n",
    "class ModelAlpha(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelAlpha, self).__init__()\n",
    "\n",
    "        self.lin_input = nn.Linear(4, 10)\n",
    "        self.lin_2 = nn.Linear(10, 10)\n",
    "        self.lin_output = nn.Linear(10, 1)\n"
   ],
   "id": "58a158e20dc3121",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4개 값을 받아 3개의 값을 출력하는 모델을 정의한다.\n",
    "# 4->20->30->20->3 총 4층으로 이뤄진 모델\n",
    "\n",
    "class ModelBravo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelBravo, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Linear(4, 20)\n",
    "        self.l2 = nn.Linear(20, 30)\n",
    "        self.l3 = nn.Linear(30, 20)\n",
    "        self.l4 = nn.Linear(20, 3)\n"
   ],
   "id": "d052ee8b1d495693",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Practice 2. 빈 모델 만들기\n",
    "\n",
    "1. `ModelCharlie` 클래스를 입력층 5, 은닉층 10, 10, 출력층 1로 네트워크를 구성해 만드세요.\n",
    "2. `ModelDelta` 클래스를 입력층 3, 은닉층 6, 12, 24, 12, 6, 3, 출력층 1로 네트워크를 구성해 만드세요.\n",
    "3. `ModelEcho` 클래스를 입력층 10, 은닉층 모두 30, 출력층 1로 구성된 총 51층 네트워크를 구성해 만들 방법을 생각해보세요.\n",
    "(힌트 - 언패킹)\n"
   ],
   "id": "947d1ae12baaae4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelCharlie(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelCharlie, self).__init__()\n",
    "        num_neurons = [5, 10, 10, 1]\n",
    "        layers = []\n",
    "        for i, n in enumerate(num_neurons[:-1]):\n",
    "            _in = num_neurons[i]\n",
    "            _out = num_neurons[i + 1]\n",
    "            layers.append(nn.Linear(_in, _out))\n",
    "\n",
    "        self.a, self.b, self.c = layers\n",
    "\n",
    "mc = ModelCharlie()\n",
    "mc"
   ],
   "id": "3f41461420062e60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelDelta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelDelta, self).__init__()\n",
    "        num_neurons = [3, 6, 12, 24, 12, 6, 3, 1]\n",
    "        layers = []\n",
    "        for i, n in enumerate(num_neurons[:-1]):\n",
    "            _in = num_neurons[i]\n",
    "            _out = num_neurons[i + 1]\n",
    "            layers.append(nn.Linear(_in, _out))\n",
    "\n",
    "        self.layer = nn.Sequential(*layers)\n",
    "\n",
    "md = ModelDelta()\n",
    "md"
   ],
   "id": "7f6bc8810eb01de5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelEcho(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelEcho, self).__init__()\n",
    "        num_neurons = [10] + [30]*49 + [1]\n",
    "        layers = []\n",
    "        for i, n in enumerate(num_neurons[:-1]):\n",
    "            _in = num_neurons[i]\n",
    "            _out = num_neurons[i + 1]\n",
    "            layers.append(nn.Linear(_in, _out))\n",
    "\n",
    "        self.layer = nn.Sequential(*layers)\n",
    "\n",
    "me = ModelEcho()\n",
    "me"
   ],
   "id": "dd06ad46e3de5a86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 순전파와 활성함수\n",
    "\n",
    "뉴럴네트워크 모델은 x값을 받아 y값을 계산하는 방법을 지정해주어야 한다."
   ],
   "id": "8f73edc9257b8e41"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelFoxtrot(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelFoxtrot, self).__init__()\n",
    "        self.lin1 = nn.Linear(4, 10)  # 입력층: 4개의 특성, 은닉층: 10개의 뉴런\n",
    "        self.lin2 = nn.Linear(10, 10)  # 은닉층: 10개의 뉴런\n",
    "        self.lin3 = nn.Linear(10, 1)   # 출력층: 1개의 뉴런\n",
    "\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.activation2 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.activation2(x)\n",
    "        return self.lin3(x)\n",
    "\n",
    "mf = ModelFoxtrot()\n",
    "t = randn(10, 4)\n",
    "print(mf(t))"
   ],
   "id": "394f59d2c3d4a13c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 활성함수\n",
    "\n",
    "1. ReLU (Rectified Linear Unit): `f(x) = max(0, x)`\n",
    "2. Sigmoid: `f(x) = 1 / (1 + exp(-x))`\n",
    "3. Tanh (Hyperbolic Tangent): `f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`\n",
    "4. Leaky ReLU: `f(x) = x if x > 0 else alpha * x` (alpha는 작은 상수)\n",
    "5. SELU (Scaled Exponential Linear Unit): `f(x) = scale * x if x > 0 else scale * alpha * (exp(x) - 1)`\n",
    "6. ELU (Exponential Linear Unit): `f(x) = x if x > 0 else alpha * (exp(x) - 1)`\n",
    "7. GELU (Gaussian Error Linear Unit): `f(x) = 0.5 * x * (1 + erf(x / sqrt(2)))` (erf는 오차 함수)\n",
    "8. Swish: `f(x) = x * sigmoid(beta * x)` (beta는 상수)\n",
    "\n",
    "이 외에도 활성함수가 여럿 있다. 이들이 각각 어디에 쓰이는지는 목적상황에 따라 다르다."
   ],
   "id": "e67b60a47f9a61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Practice 3. 순전파 구현하기\n",
    "\n",
    "1. `ModelGolf` (5, 6, 3) 네트워크와 ReLU 활성함수를 사용한 순전파를 구현하세요.\n",
    "2. `ModelHotel` (3, 6, 9, 12, 1) 네트워크와 LeakyReLU 활성함수를 사용한 순전파를 구현하세요.\n",
    "3. `ModelIndia` (10, 20, 30, 20, 10, 5, 1) 네트워크와 여러가지 활성함수를 사용한 순전파를 구현하세요."
   ],
   "id": "824391e05cb06a64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ModelGolf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelGolf, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(5, 6),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "mg = ModelGolf()"
   ],
   "id": "7bdefc62bf9c6b5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (10, 20, 30, 20, 10, 5, 1)\n",
    "class ModelIndia(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelIndia, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 30),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(30, 20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "id": "223e38aab6d4e592",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 훈련함수\n",
    "\n",
    "훈련용 함수.. 구현"
   ],
   "id": "cedea5a7b963e8c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn, Tensor\n",
    "from torch.nn import Module\n",
    "from torch.optim import Adam\n",
    "\n",
    "class TitanicModel(Module):\n",
    "  def __init__(self):\n",
    "    super(TitanicModel, self).__init__()\n",
    "\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Linear(11, 60),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(60, 20),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(20, 1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "\n",
    "model = TitanicModel()\n",
    "model"
   ],
   "id": "b7891f55ebba637d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "optimizer = Adam(model.parameters(), lr=0.0005)\n",
    "# 로스함수\n",
    "from torch.nn import BCELoss, BCEWithLogitsLoss\n",
    "from torch import no_grad\n",
    "\n",
    "loss_fn = BCEWithLogitsLoss()        # pos_weight=... 가능\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(500):\n",
    "    for x, y in for_train:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # test값과의 비교\n",
    "    with no_grad():\n",
    "        train_pred = model(xs_train_tensor)\n",
    "        train_loss = loss_fn(train_pred, ys_train_tensor.unsqueeze(1))\n",
    "\n",
    "        test_pred = model(xs_test_tensor)\n",
    "        test_loss = loss_fn(test_pred, ys_test_tensor.unsqueeze(1))\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "    print(\"Epoch:\", epoch + 1, \"ended\")"
   ],
   "id": "17f1c69cfe0cd22e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(test_losses, label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "fcaf9272704151f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('./sea/서해 2020 01월.csv', encoding='cp949')\n",
    "df"
   ],
   "id": "4c465b3bc7939a6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "series = pd.Series([])\n",
    "for month in '01 02 03 04 05 06 07 08 09 10 11 12'.split():\n",
    "    df = pd.concat([df, pd.read_csv(f'./sea/서해 2020 {month}월.csv', encoding='cp949')])\n",
    "\n",
    "    gs = df[df.관측소 == '군산 신시도(egsi4)']\n",
    "    gs_surface = gs['표층수온(℃)']\n",
    "\n",
    "    # series에 병합\n",
    "    series = pd.concat([series, gs_surface], ignore_index=True)\n",
    "\n",
    "plt.plot(series)"
   ],
   "id": "29c22fcb5e2f1af2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def major_sine(x, a, b, c, d):\n",
    "    return a * np.sin(b * x + c) + d\n",
    "\n",
    "import numpy as np\n",
    "x = np.arange(len(series))\n",
    "popt, _ = curve_fit(major_sine, x, series, p0=[1, 0.1, 0, 10])\n"
   ],
   "id": "1651c12a2553193e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fitted_sine(x):\n",
    "    return major_sine(x, *popt)\n",
    "\n",
    "plt.plot(x, series, label='Observed')\n",
    "plt.plot(x, fitted_sine(x), label='Fitted Sine Wave', color='red')"
   ],
   "id": "b0d43dfc446b2e10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4efeaa38aee7ef66",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
